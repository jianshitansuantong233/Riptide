{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3pxnet.ipynb","provenance":[],"collapsed_sections":[],"background_execution":"on","authorship_tag":"ABX9TyN9FqyefkI6MI5k/++cYMpF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ShvqKTRnLCHe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640050086239,"user_tz":480,"elapsed":2221,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"730fc6e0-0760-4979-8fcb-0589abf3ca58"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Riptide\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd /content/drive/MyDrive/'Colab Notebooks'/Riptide"]},{"cell_type":"code","source":["!apt-get update\n","!apt-get install -y python3 python3-dev python3-setuptools gcc libtinfo-dev zlib1g-dev\n","!apt-get install -y build-essential cmake libedit-dev libxml2-dev"],"metadata":{"id":"uIinWeUzLbNf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640050101008,"user_tz":480,"elapsed":14773,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"162bdefb-f75d-497a-8761-6d499f92f755"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r            \rGet:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\r            \rHit:3 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.39)] [Co\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","\r0% [4 InRelease 63.4 kB/88.7 kB 71%] [Connecting to security.ubuntu.com (91.189\r0% [1 InRelease gpgv 242 kB] [4 InRelease 72.1 kB/88.7 kB 81%] [Connecting to s\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","\r0% [1 InRelease gpgv 242 kB] [6 InRelease 9,844 B/74.6 kB 13%] [Connecting to s\r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.39)]\r                                                                               \rGet:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,821 kB]\n","Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,230 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n","Get:19 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [73.9 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.6 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.6 kB]\n","Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n","Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [833 kB]\n","Get:25 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n","Get:26 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n","Get:27 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,452 kB]\n","Fetched 13.8 MB in 3s (3,974 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n","zlib1g-dev set to manually installed.\n","gcc is already the newest version (4:7.4.0-1ubuntu2.3).\n","gcc set to manually installed.\n","libtinfo-dev is already the newest version (6.1-1ubuntu1.18.04).\n","libtinfo-dev set to manually installed.\n","python3 is already the newest version (3.6.7-1~18.04).\n","python3 set to manually installed.\n","python3-dev is already the newest version (3.6.7-1~18.04).\n","python3-dev set to manually installed.\n","The following additional packages will be installed:\n","  python3-pkg-resources\n","Suggested packages:\n","  python-setuptools-doc\n","The following NEW packages will be installed:\n","  python3-pkg-resources python3-setuptools\n","0 upgraded, 2 newly installed, 0 to remove and 82 not upgraded.\n","Need to get 346 kB of archives.\n","After this operation, 1,848 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n","Fetched 346 kB in 0s (4,396 kB/s)\n","Selecting previously unselected package python3-pkg-resources.\n","(Reading database ... 155222 files and directories currently installed.)\n","Preparing to unpack .../python3-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python3-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python3-setuptools.\n","Preparing to unpack .../python3-setuptools_39.0.1-2_all.deb ...\n","Unpacking python3-setuptools (39.0.1-2) ...\n","Setting up python3-pkg-resources (39.0.1-2) ...\n","Setting up python3-setuptools (39.0.1-2) ...\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","build-essential is already the newest version (12.4ubuntu1).\n","cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n","libxml2-dev is already the newest version (2.9.4+dfsg1-6.1ubuntu1.4).\n","The following additional packages will be installed:\n","  libbsd-dev\n","The following NEW packages will be installed:\n","  libbsd-dev libedit-dev\n","0 upgraded, 2 newly installed, 0 to remove and 82 not upgraded.\n","Need to get 249 kB of archives.\n","After this operation, 1,135 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbsd-dev amd64 0.8.7-1ubuntu0.1 [150 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libedit-dev amd64 3.1-20170329-1 [99.1 kB]\n","Fetched 249 kB in 0s (1,911 kB/s)\n","Selecting previously unselected package libbsd-dev:amd64.\n","(Reading database ... 155335 files and directories currently installed.)\n","Preparing to unpack .../libbsd-dev_0.8.7-1ubuntu0.1_amd64.deb ...\n","Unpacking libbsd-dev:amd64 (0.8.7-1ubuntu0.1) ...\n","Selecting previously unselected package libedit-dev:amd64.\n","Preparing to unpack .../libedit-dev_3.1-20170329-1_amd64.deb ...\n","Unpacking libedit-dev:amd64 (3.1-20170329-1) ...\n","Setting up libbsd-dev:amd64 (0.8.7-1ubuntu0.1) ...\n","Setting up libedit-dev:amd64 (3.1-20170329-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","source":["!pip3 install --user numpy decorator attrs tornado psutil xgboost     \n","!pip install tensorflow==2.1"],"metadata":{"id":"FhvmT8xfLuZ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640050165581,"user_tz":480,"elapsed":64576,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"9c5f4444-13c4-4fa3-ac8f-c49c718d02e5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (21.2.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (5.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n","Collecting tensorflow==2.1\n","  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n","\u001b[K     |████████████████████████████████| 421.8 MB 26 kB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (3.17.3)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.42.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (0.8.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (0.12.0)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.4.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.13.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.1.2)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 52.2 MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (0.2.0)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 67.1 MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (0.37.0)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1) (1.19.5)\n","Collecting keras-applications>=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1) (3.1.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (57.4.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.3.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.10.0.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.1.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1) (1.5.2)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=7676ff2992538d9005226ff06f8d3baf693817a01c0f6131716b28f91672bbb7\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.7.0\n","    Uninstalling tensorflow-estimator-2.7.0:\n","      Successfully uninstalled tensorflow-estimator-2.7.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.7.0\n","    Uninstalling tensorboard-2.7.0:\n","      Successfully uninstalled tensorboard-2.7.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.7.0\n","    Uninstalling tensorflow-2.7.0:\n","      Successfully uninstalled tensorflow-2.7.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"]}]},{"cell_type":"code","source":["%cd tvm\n","%mkdir build\n","%cp cmake/config.cmake build\n","%cd build\n","%pwd"],"metadata":{"id":"AxjXH__rMLdc","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1640050166632,"user_tz":480,"elapsed":1060,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"aef723b5-2fb6-4d4b-9405-3449329c531d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Riptide/tvm\n","mkdir: cannot create directory ‘build’: File exists\n","/content/drive/MyDrive/Colab Notebooks/Riptide/tvm/build\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks/Riptide/tvm/build'"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!cmake ..\n","!make -j4"],"metadata":{"id":"sxKj4-uaMbwI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640050168044,"user_tz":480,"elapsed":1417,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"b4189d7c-4c53-43e1-db4f-58525fdef0d5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["CMake Error: The current CMakeCache.txt directory /content/drive/MyDrive/Colab Notebooks/Riptide/tvm/build/CMakeCache.txt is different than the directory /mnt/e/Riptide/tvm/build where CMakeCache.txt was created. This may result in binaries being created in the wrong place. If you are not sure, reedit the CMakeCache.txt\n","CMake Error: The source \"/content/drive/MyDrive/Colab Notebooks/Riptide/tvm/CMakeLists.txt\" does not match the source \"/mnt/e/Riptide/tvm/CMakeLists.txt\" used to generate cache.  Re-run cmake with a different source directory.\n","CMake Error: The source directory \"/mnt/e/Riptide/tvm\" does not exist.\n","Specify --help for usage, or press the help button on the CMake GUI.\n","Makefile:8230: recipe for target 'cmake_check_build_system' failed\n","make: *** [cmake_check_build_system] Error 1\n"]}]},{"cell_type":"code","source":["%env TVM_HOME=/content/drive/MyDrive/Colab Notebooks/Riptide/tvm\n","%env PYTHONPATH=$/env/python:/content/drive/MyDrive/Colab Notebooks/Riptide:$TVM_HOME/python:$TVM_HOME/topi/python:$PYTHONPATH"],"metadata":{"id":"BQOnvnnSQI8c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640050168044,"user_tz":480,"elapsed":7,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"c49900ae-4d41-4332-acd7-5be6ea735c3b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["env: TVM_HOME=/content/drive/MyDrive/Colab Notebooks/Riptide/tvm\n","env: PYTHONPATH=$/env/python:/content/drive/MyDrive/Colab Notebooks/Riptide:$TVM_HOME/python:$TVM_HOME/topi/python:$PYTHONPATH\n"]}]},{"cell_type":"code","source":["%pwd"],"metadata":{"id":"jcer1_HPNx_3","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1640050168045,"user_tz":480,"elapsed":6,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"a6f99707-47dd-49de-c6d3-9ebe7e7c38d9"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks/Riptide/tvm/build'"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/'Colab Notebooks'/Riptide\n","! echo $PYTHONPATH"],"metadata":{"id":"tJKJt7ZiPso0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640050168733,"user_tz":480,"elapsed":694,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"3e98668b-bcef-4d28-a005-2a112ada0494"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Riptide\n","$/env/python:/content/drive/MyDrive/Colab Notebooks/Riptide:$TVM_HOME/python:$TVM_HOME/topi/python:$PYTHONPATH\n"]}]},{"cell_type":"code","source":["!python scripts/train_imagenet.py --model cnn_medium --experiment 2A1W --gpus 0,1,2,3 --binary --bits 2 --model_dir ~/models"],"metadata":{"id":"MmFQIG-GMlYe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640050398136,"user_tz":480,"elapsed":229406,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"638f1dac-032b-4c5d-c8c7-ebbfd3fd9009"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-12-21 01:29:30.464691: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2021-12-21 01:29:30.464869: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2021-12-21 01:29:30.464889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","I1221 01:29:41.885535 139879459252096 thread_helper.py:10] Logical CPU cores: 2\n","I1221 01:29:41.886461 139879459252096 thread_helper.py:17] TF_GPU_THREAD_COUNT: 1\n","I1221 01:29:41.886582 139879459252096 thread_helper.py:18] TF_GPU_THREAD_MODE: gpu_private\n","2021-12-21 01:29:41.889722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-12-21 01:29:41.949845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:41.950496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-12-21 01:29:41.992809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-12-21 01:29:42.152384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-12-21 01:29:42.182374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-12-21 01:29:42.198176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-12-21 01:29:42.386585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-12-21 01:29:42.434757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-12-21 01:29:42.762080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-12-21 01:29:42.762319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:42.763070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:42.763654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n","2021-12-21 01:29:42.764087: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2021-12-21 01:29:42.769234: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000160000 Hz\n","2021-12-21 01:29:42.769497: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560efc586d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-12-21 01:29:42.769531: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-12-21 01:29:42.879298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:42.880523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560efc586f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-12-21 01:29:42.880558: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n","2021-12-21 01:29:42.880842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:42.881481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-12-21 01:29:42.881557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-12-21 01:29:42.881581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-12-21 01:29:42.881600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-12-21 01:29:42.881619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-12-21 01:29:42.881637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-12-21 01:29:42.881654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-12-21 01:29:42.881673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-12-21 01:29:42.881744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:42.882339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:42.882918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n","2021-12-21 01:29:42.883033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-12-21 01:29:42.884850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-12-21 01:29:42.884882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n","2021-12-21 01:29:42.884903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n","2021-12-21 01:29:42.885079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:42.885821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:29:42.886555: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-12-21 01:29:42.886605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I1221 01:29:42.888899 139879459252096 mirrored_strategy.py:435] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Initializing RunConfig with distribution strategies.\n","I1221 01:29:42.889521 139879459252096 run_config.py:566] Initializing RunConfig with distribution strategies.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I1221 01:29:42.889693 139879459252096 estimator_training.py:167] Not using Distribute Coordinator.\n","INFO:tensorflow:Using config: {'_model_dir': '/root/models/cnn_medium_2A1W', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 3600, '_session_config': intra_op_parallelism_threads: -2\n","inter_op_parallelism_threads: -2\n","gpu_options {\n","  allow_growth: true\n","}\n","allow_soft_placement: true\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f37c2eaacd0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n","I1221 01:29:42.890262 139879459252096 estimator.py:216] Using config: {'_model_dir': '/root/models/cnn_medium_2A1W', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 3600, '_session_config': intra_op_parallelism_threads: -2\n","inter_op_parallelism_threads: -2\n","gpu_options {\n","  allow_growth: true\n","}\n","allow_soft_placement: true\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f37c2eaacd0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I1221 01:29:42.890872 139879459252096 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I1221 01:29:42.891170 139879459252096 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 3600.\n","I1221 01:29:42.891573 139879459252096 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 3600.\n","2021-12-21 01:29:42.893565: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\n","2021-12-21 01:29:43.020222: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\n","2021-12-21 01:29:43.167054: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\n","I1221 01:29:43.301904 139879459252096 dataset_info.py:434] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: cifar10/3.0.2\n","2021-12-21 01:29:43.305981: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\n","2021-12-21 01:29:43.594146: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\n","2021-12-21 01:29:43.894188: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\n","I1221 01:29:44.154602 139879459252096 dataset_info.py:361] Load dataset info from /tmp/tmpfx5g_etgtfds\n","I1221 01:29:44.157707 139879459252096 dataset_info.py:405] Field info.citation from disk and from code do not match. Keeping the one from code.\n","I1221 01:29:44.158188 139879459252096 dataset_builder.py:357] Generating dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n","\u001b[1mDownloading and preparing dataset cifar10/3.0.2 (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to /root/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n","2021-12-21 01:29:44.300570: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\n","2021-12-21 01:29:44.430987: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\n","Dl Completed...: 0 url [00:00, ? url/s]\n","Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI1221 01:29:44.568583 139879459252096 download_manager.py:476] Downloading https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz into /root/tensorflow_datasets/downloads/cs.toronto.edu_kriz_cifar-10-binaryODHPtIjLh3oLcXirEISTO7dkzyKjRCuol6lV8Wc6C7s.tar.gz.tmp.5e1b3f6316d044f9b09251fb7074fd57...\n","Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n","Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n","Dl Size...:   0% 0/162 [00:00<?, ? MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n","Dl Size...:   1% 1/162 [00:00<02:33,  1.05 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   1% 2/162 [00:01<02:32,  1.05 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   2% 3/162 [00:01<00:45,  3.48 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   2% 4/162 [00:01<00:45,  3.48 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   3% 5/162 [00:01<00:45,  3.48 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   4% 6/162 [00:01<00:22,  6.87 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   4% 7/162 [00:01<00:22,  6.87 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   5% 8/162 [00:01<00:22,  6.87 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   6% 9/162 [00:01<00:14, 10.72 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   6% 10/162 [00:01<00:14, 10.72 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   7% 11/162 [00:01<00:14, 10.72 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   7% 12/162 [00:01<00:13, 10.72 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   8% 13/162 [00:01<00:09, 16.07 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   9% 14/162 [00:01<00:09, 16.07 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:   9% 15/162 [00:01<00:09, 16.07 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  10% 16/162 [00:01<00:09, 16.07 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  10% 17/162 [00:01<00:07, 18.76 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  11% 18/162 [00:01<00:07, 18.76 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  12% 19/162 [00:01<00:07, 18.76 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  12% 20/162 [00:01<00:07, 18.76 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  13% 21/162 [00:01<00:06, 22.59 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  14% 22/162 [00:01<00:06, 22.59 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  14% 23/162 [00:01<00:06, 22.59 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  15% 24/162 [00:01<00:06, 22.59 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  15% 25/162 [00:01<00:05, 25.20 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  16% 26/162 [00:01<00:05, 25.20 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  17% 27/162 [00:01<00:05, 25.20 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  17% 28/162 [00:01<00:05, 24.39 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n","Dl Size...:  18% 29/162 [00:01<00:05, 24.39 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  19% 30/162 [00:02<00:05, 24.39 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  19% 31/162 [00:02<00:05, 24.39 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  20% 32/162 [00:02<00:04, 26.69 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  20% 33/162 [00:02<00:04, 26.69 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  21% 34/162 [00:02<00:04, 26.69 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  22% 35/162 [00:02<00:04, 26.69 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  22% 36/162 [00:02<00:04, 29.08 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  23% 37/162 [00:02<00:04, 29.08 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  23% 38/162 [00:02<00:04, 29.08 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  24% 39/162 [00:02<00:04, 29.08 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  25% 40/162 [00:02<00:04, 28.35 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  25% 41/162 [00:02<00:04, 28.35 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  26% 42/162 [00:02<00:04, 28.35 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  27% 43/162 [00:02<00:04, 28.35 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  27% 44/162 [00:02<00:04, 28.58 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  28% 45/162 [00:02<00:04, 28.58 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  28% 46/162 [00:02<00:04, 28.58 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  29% 47/162 [00:02<00:04, 28.58 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  30% 48/162 [00:02<00:03, 30.39 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  30% 49/162 [00:02<00:03, 30.39 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  31% 50/162 [00:02<00:03, 30.39 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  31% 51/162 [00:02<00:03, 30.39 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  32% 52/162 [00:02<00:03, 29.12 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  33% 53/162 [00:02<00:03, 29.12 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  33% 54/162 [00:02<00:03, 29.12 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  34% 55/162 [00:02<00:03, 29.12 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  35% 56/162 [00:02<00:03, 29.93 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  35% 57/162 [00:02<00:03, 29.93 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  36% 58/162 [00:02<00:03, 29.93 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n","Dl Size...:  36% 59/162 [00:02<00:03, 29.93 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  37% 60/162 [00:03<00:03, 30.23 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  38% 61/162 [00:03<00:03, 30.23 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  38% 62/162 [00:03<00:03, 30.23 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  39% 63/162 [00:03<00:03, 30.23 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  40% 64/162 [00:03<00:03, 30.01 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  40% 65/162 [00:03<00:03, 30.01 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  41% 66/162 [00:03<00:03, 30.01 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  41% 67/162 [00:03<00:03, 30.01 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  42% 68/162 [00:03<00:03, 30.99 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  43% 69/162 [00:03<00:03, 30.99 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  43% 70/162 [00:03<00:02, 30.99 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  44% 71/162 [00:03<00:02, 30.99 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  44% 72/162 [00:03<00:02, 30.28 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  45% 73/162 [00:03<00:02, 30.28 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  46% 74/162 [00:03<00:02, 30.28 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  46% 75/162 [00:03<00:02, 30.28 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  47% 76/162 [00:03<00:02, 30.90 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  48% 77/162 [00:03<00:02, 30.90 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  48% 78/162 [00:03<00:02, 30.90 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  49% 79/162 [00:03<00:02, 30.90 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  49% 80/162 [00:03<00:02, 30.79 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  50% 81/162 [00:03<00:02, 30.79 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  51% 82/162 [00:03<00:02, 30.79 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  51% 83/162 [00:03<00:02, 30.79 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  52% 84/162 [00:03<00:02, 30.14 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  52% 85/162 [00:03<00:02, 30.14 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  53% 86/162 [00:03<00:02, 30.14 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  54% 87/162 [00:03<00:02, 30.14 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  54% 88/162 [00:03<00:02, 30.40 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  55% 89/162 [00:03<00:02, 30.40 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n","Dl Size...:  56% 90/162 [00:03<00:02, 30.40 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  56% 91/162 [00:04<00:02, 30.40 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  57% 92/162 [00:04<00:02, 30.49 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  57% 93/162 [00:04<00:02, 30.49 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  58% 94/162 [00:04<00:02, 30.49 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  59% 95/162 [00:04<00:02, 30.49 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  59% 96/162 [00:04<00:02, 30.60 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  60% 97/162 [00:04<00:02, 30.60 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  60% 98/162 [00:04<00:02, 30.60 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  61% 99/162 [00:04<00:02, 30.60 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  62% 100/162 [00:04<00:02, 30.22 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  62% 101/162 [00:04<00:02, 30.22 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  63% 102/162 [00:04<00:01, 30.22 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  64% 103/162 [00:04<00:01, 30.22 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  64% 104/162 [00:04<00:01, 30.65 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  65% 105/162 [00:04<00:01, 30.65 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  65% 106/162 [00:04<00:01, 30.65 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  66% 107/162 [00:04<00:01, 30.65 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  67% 108/162 [00:04<00:01, 30.42 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  67% 109/162 [00:04<00:01, 30.42 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  68% 110/162 [00:04<00:01, 30.42 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  69% 111/162 [00:04<00:01, 30.42 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  69% 112/162 [00:04<00:01, 30.34 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  70% 113/162 [00:04<00:01, 30.34 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  70% 114/162 [00:04<00:01, 30.34 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  71% 115/162 [00:04<00:01, 30.34 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  72% 116/162 [00:04<00:01, 31.30 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  72% 117/162 [00:04<00:01, 31.30 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  73% 118/162 [00:04<00:01, 31.30 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  73% 119/162 [00:04<00:01, 31.30 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n","Dl Size...:  74% 120/162 [00:04<00:01, 30.69 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  75% 121/162 [00:05<00:01, 30.69 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  75% 122/162 [00:05<00:01, 30.69 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  76% 123/162 [00:05<00:01, 30.69 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  77% 124/162 [00:05<00:01, 30.90 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  77% 125/162 [00:05<00:01, 30.90 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  78% 126/162 [00:05<00:01, 30.90 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  78% 127/162 [00:05<00:01, 30.90 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  79% 128/162 [00:05<00:01, 31.19 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  80% 129/162 [00:05<00:01, 31.19 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  80% 130/162 [00:05<00:01, 31.19 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  81% 131/162 [00:05<00:00, 31.19 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  81% 132/162 [00:05<00:01, 29.87 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  82% 133/162 [00:05<00:00, 29.87 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  83% 134/162 [00:05<00:00, 29.87 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  83% 135/162 [00:05<00:00, 29.87 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  84% 136/162 [00:05<00:00, 30.91 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  85% 137/162 [00:05<00:00, 30.91 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  85% 138/162 [00:05<00:00, 30.91 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  86% 139/162 [00:05<00:00, 30.91 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  86% 140/162 [00:05<00:00, 30.36 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  87% 141/162 [00:05<00:00, 30.36 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  88% 142/162 [00:05<00:00, 30.36 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  88% 143/162 [00:05<00:00, 30.36 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  89% 144/162 [00:05<00:00, 30.52 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  90% 145/162 [00:05<00:00, 30.52 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  90% 146/162 [00:05<00:00, 30.52 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  91% 147/162 [00:05<00:00, 30.52 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  91% 148/162 [00:05<00:00, 30.38 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  92% 149/162 [00:05<00:00, 30.38 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  93% 150/162 [00:05<00:00, 30.38 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n","Dl Size...:  93% 151/162 [00:05<00:00, 30.38 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  94% 152/162 [00:06<00:00, 30.05 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  94% 153/162 [00:06<00:00, 30.05 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  95% 154/162 [00:06<00:00, 30.05 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  96% 155/162 [00:06<00:00, 30.05 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  96% 156/162 [00:06<00:00, 30.16 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  97% 157/162 [00:06<00:00, 30.16 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  98% 158/162 [00:06<00:00, 30.16 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  98% 159/162 [00:06<00:00, 30.16 MiB/s]\u001b[A\n","\n","Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  99% 160/162 [00:06<00:00, 30.07 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...:  99% 161/162 [00:06<00:00, 30.07 MiB/s]\u001b[A\n","\n","Dl Completed...:   0% 0/1 [00:06<?, ? url/s]\n","Dl Size...: 100% 162/162 [00:06<00:00, 30.07 MiB/s]\u001b[A\n","\n","Dl Completed...: 100% 1/1 [00:06<00:00,  6.36s/ url]\n","Dl Size...: 100% 162/162 [00:06<00:00, 30.07 MiB/s]\u001b[A\n","\n","Dl Completed...: 100% 1/1 [00:06<00:00,  6.36s/ url]\n","Dl Size...: 100% 162/162 [00:06<00:00, 30.07 MiB/s]\u001b[A\n","\n","Extraction completed...:   0% 0/1 [00:06<?, ? file/s]\u001b[A\u001b[A\n","\n","Dl Completed...: 100% 1/1 [00:08<00:00,  6.36s/ url]\n","Dl Size...: 100% 162/162 [00:08<00:00, 30.07 MiB/s]\u001b[A\n","\n","Extraction completed...: 100% 1/1 [00:08<00:00,  8.37s/ file]\u001b[A\u001b[A\n","Extraction completed...: 100% 1/1 [00:08<00:00,  8.38s/ file]\n","\n","Dl Size...: 100% 162/162 [00:08<00:00, 19.34 MiB/s]\n","\n","Dl Completed...: 100% 1/1 [00:08<00:00,  8.38s/ url]\n","I1221 01:29:52.944547 139879459252096 dataset_builder.py:970] Generating split train\n","0 examples [00:00, ? examples/s]2021-12-21 01:29:52.993396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-12-21 01:29:52.993443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      \n","Shuffling and writing examples to /root/tensorflow_datasets/cifar10/3.0.2.incomplete9LUP4S/cifar10-train.tfrecord\n"," 78% 39163/50000 [00:00<00:00, 137106.75 examples/s]I1221 01:30:41.582961 139879459252096 tfrecords_writer.py:226] Done writing /root/tensorflow_datasets/cifar10/3.0.2.incomplete9LUP4S/cifar10-train.tfrecord. Shard lengths: [50000]\n","I1221 01:30:41.614100 139879459252096 dataset_builder.py:970] Generating split test\n","Shuffling and writing examples to /root/tensorflow_datasets/cifar10/3.0.2.incomplete9LUP4S/cifar10-test.tfrecord\n","  0% 0/10000 [00:00<?, ? examples/s]I1221 01:30:50.831966 139879459252096 tfrecords_writer.py:226] Done writing /root/tensorflow_datasets/cifar10/3.0.2.incomplete9LUP4S/cifar10-test.tfrecord. Shard lengths: [10000]\n","I1221 01:30:50.838061 139879459252096 dataset_builder.py:412] Skipping computing stats for mode ComputeStatsMode.SKIP.\n","\u001b[1mDataset cifar10 downloaded and prepared to /root/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n","I1221 01:30:50.839658 139879459252096 dataset_builder.py:511] Constructing tf.data.Dataset for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/image_ops_impl.py:2514: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W1221 01:30:51.958971 139879459252096 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/image_ops_impl.py:2514: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","W1221 01:30:52.618752 139879459252096 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:52.627806 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Calling model_fn.\n","I1221 01:30:52.636584 139875349747456 estimator.py:1151] Calling model_fn.\n","WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/Riptide/riptide/binary/binary_layers.py:536: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","W1221 01:30:55.927005 139875349747456 deprecation.py:323] From /content/drive/MyDrive/Colab Notebooks/Riptide/riptide/binary/binary_layers.py:536: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/Riptide/riptide/binary/binary_layers.py:702: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`inputs` is now automatically inferred\n","W1221 01:30:55.935603 139875349747456 deprecation.py:506] From /content/drive/MyDrive/Colab Notebooks/Riptide/riptide/binary/binary_layers.py:702: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`inputs` is now automatically inferred\n","Tensor(\"cnn__medium/softmax/Softmax:0\", shape=(None, 10), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Tensor(\"cond_1/Identity_1:0\", shape=(None,), dtype=int64, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:56.957940 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:56.959453 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:56.961264 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:56.962642 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:56.976841 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:56.978207 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:56.979984 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:56.981341 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Done calling model_fn.\n","I1221 01:30:57.526366 139875349747456 estimator.py:1153] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I1221 01:30:57.569080 139879459252096 basic_session_run_hooks.py:546] Create CheckpointSaverHook.\n","INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","I1221 01:30:57.875329 139879459252096 cross_device_ops.py:439] Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Graph was finalized.\n","I1221 01:30:58.021983 139879459252096 monitored_session.py:246] Graph was finalized.\n","2021-12-21 01:30:58.022769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:30:58.023398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-12-21 01:30:58.023483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-12-21 01:30:58.023507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-12-21 01:30:58.023526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-12-21 01:30:58.023552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-12-21 01:30:58.023573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-12-21 01:30:58.023591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-12-21 01:30:58.023609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-12-21 01:30:58.023691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:30:58.024301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:30:58.024830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n","2021-12-21 01:30:58.024874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-12-21 01:30:58.024889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n","2021-12-21 01:30:58.024898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n","2021-12-21 01:30:58.024991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:30:58.025566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:30:58.026190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","INFO:tensorflow:Running local_init_op.\n","I1221 01:30:58.703226 139879459252096 session_manager.py:504] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1221 01:30:58.738985 139879459252096 session_manager.py:507] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /root/models/cnn_medium_2A1W/model.ckpt.\n","I1221 01:30:59.931546 139879459252096 basic_session_run_hooks.py:613] Saving checkpoints for 0 into /root/models/cnn_medium_2A1W/model.ckpt.\n","2021-12-21 01:31:03.342579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-12-21 01:31:06.046357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","INFO:tensorflow:loss = 2.8551807, step = 0\n","I1221 01:31:08.307288 139879459252096 basic_session_run_hooks.py:262] loss = 2.8551807, step = 0\n","INFO:tensorflow:global_step/sec: 22.2997\n","I1221 01:31:30.726516 139879459252096 basic_session_run_hooks.py:700] global_step/sec: 22.2997\n","INFO:tensorflow:loss = 1.703444, step = 500 (22.421 sec)\n","I1221 01:31:30.728295 139879459252096 basic_session_run_hooks.py:260] loss = 1.703444, step = 500 (22.421 sec)\n","INFO:tensorflow:global_step/sec: 30.5283\n","I1221 01:31:47.104729 139879459252096 basic_session_run_hooks.py:700] global_step/sec: 30.5283\n","INFO:tensorflow:loss = 1.8435905, step = 1000 (16.378 sec)\n","I1221 01:31:47.106359 139879459252096 basic_session_run_hooks.py:260] loss = 1.8435905, step = 1000 (16.378 sec)\n","INFO:tensorflow:global_step/sec: 33.3018\n","I1221 01:32:02.118985 139879459252096 basic_session_run_hooks.py:700] global_step/sec: 33.3018\n","INFO:tensorflow:loss = 1.8265159, step = 1500 (15.014 sec)\n","I1221 01:32:02.120782 139879459252096 basic_session_run_hooks.py:260] loss = 1.8265159, step = 1500 (15.014 sec)\n","INFO:tensorflow:global_step/sec: 33.4185\n","I1221 01:32:17.080677 139879459252096 basic_session_run_hooks.py:700] global_step/sec: 33.4185\n","INFO:tensorflow:loss = 1.8138161, step = 2000 (14.962 sec)\n","I1221 01:32:17.082408 139879459252096 basic_session_run_hooks.py:260] loss = 1.8138161, step = 2000 (14.962 sec)\n","INFO:tensorflow:global_step/sec: 33.6596\n","I1221 01:32:31.935257 139879459252096 basic_session_run_hooks.py:700] global_step/sec: 33.6596\n","INFO:tensorflow:loss = 1.713373, step = 2500 (14.854 sec)\n","I1221 01:32:31.936856 139879459252096 basic_session_run_hooks.py:260] loss = 1.713373, step = 2500 (14.854 sec)\n","INFO:tensorflow:global_step/sec: 33.4736\n","I1221 01:32:46.872419 139879459252096 basic_session_run_hooks.py:700] global_step/sec: 33.4736\n","INFO:tensorflow:loss = 1.5895245, step = 3000 (14.937 sec)\n","I1221 01:32:46.874135 139879459252096 basic_session_run_hooks.py:260] loss = 1.5895245, step = 3000 (14.937 sec)\n","INFO:tensorflow:global_step/sec: 33.673\n","I1221 01:33:01.721097 139879459252096 basic_session_run_hooks.py:700] global_step/sec: 33.673\n","INFO:tensorflow:loss = 1.6260386, step = 3500 (14.849 sec)\n","I1221 01:33:01.722842 139879459252096 basic_session_run_hooks.py:260] loss = 1.6260386, step = 3500 (14.849 sec)\n","INFO:tensorflow:Saving checkpoints for 3910 into /root/models/cnn_medium_2A1W/model.ckpt.\n","I1221 01:33:12.671994 139879459252096 basic_session_run_hooks.py:613] Saving checkpoints for 3910 into /root/models/cnn_medium_2A1W/model.ckpt.\n","I1221 01:33:12.918187 139879459252096 dataset_info.py:361] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n","I1221 01:33:12.920132 139879459252096 dataset_builder.py:299] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n","I1221 01:33:12.920272 139879459252096 dataset_builder.py:511] Constructing tf.data.Dataset for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n","INFO:tensorflow:Calling model_fn.\n","I1221 01:33:13.247117 139879459252096 estimator.py:1151] Calling model_fn.\n","Tensor(\"cnn__medium/softmax/Softmax:0\", shape=(None, 10), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=int64)\n","INFO:tensorflow:Done calling model_fn.\n","I1221 01:33:14.229015 139879459252096 estimator.py:1153] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-12-21T01:33:14Z\n","I1221 01:33:14.245038 139879459252096 evaluation.py:255] Starting evaluation at 2021-12-21T01:33:14Z\n","INFO:tensorflow:Graph was finalized.\n","I1221 01:33:14.319551 139879459252096 monitored_session.py:246] Graph was finalized.\n","2021-12-21 01:33:14.320319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:33:14.320873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-12-21 01:33:14.320961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-12-21 01:33:14.320983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-12-21 01:33:14.321004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-12-21 01:33:14.321026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-12-21 01:33:14.321045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-12-21 01:33:14.321064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-12-21 01:33:14.321083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-12-21 01:33:14.321160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:33:14.321648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:33:14.322141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n","2021-12-21 01:33:14.322191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-12-21 01:33:14.322205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n","2021-12-21 01:33:14.322215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n","2021-12-21 01:33:14.322313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:33:14.322812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-21 01:33:14.323300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /root/models/cnn_medium_2A1W/model.ckpt-3910\n","I1221 01:33:14.324420 139879459252096 saver.py:1284] Restoring parameters from /root/models/cnn_medium_2A1W/model.ckpt-3910\n","INFO:tensorflow:Running local_init_op.\n","I1221 01:33:14.489298 139879459252096 session_manager.py:504] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1221 01:33:14.515249 139879459252096 session_manager.py:507] Done running local_init_op.\n","INFO:tensorflow:Evaluation [10/100]\n","I1221 01:33:15.123845 139879459252096 evaluation.py:167] Evaluation [10/100]\n","INFO:tensorflow:Evaluation [20/100]\n","I1221 01:33:15.293837 139879459252096 evaluation.py:167] Evaluation [20/100]\n","INFO:tensorflow:Evaluation [30/100]\n","I1221 01:33:15.465142 139879459252096 evaluation.py:167] Evaluation [30/100]\n","INFO:tensorflow:Evaluation [40/100]\n","I1221 01:33:15.627905 139879459252096 evaluation.py:167] Evaluation [40/100]\n","INFO:tensorflow:Evaluation [50/100]\n","I1221 01:33:15.801881 139879459252096 evaluation.py:167] Evaluation [50/100]\n","INFO:tensorflow:Evaluation [60/100]\n","I1221 01:33:15.967651 139879459252096 evaluation.py:167] Evaluation [60/100]\n","INFO:tensorflow:Evaluation [70/100]\n","I1221 01:33:16.139118 139879459252096 evaluation.py:167] Evaluation [70/100]\n","INFO:tensorflow:Evaluation [80/100]\n","I1221 01:33:16.299618 139879459252096 evaluation.py:167] Evaluation [80/100]\n","INFO:tensorflow:Evaluation [90/100]\n","I1221 01:33:16.454821 139879459252096 evaluation.py:167] Evaluation [90/100]\n","INFO:tensorflow:Evaluation [100/100]\n","I1221 01:33:16.622985 139879459252096 evaluation.py:167] Evaluation [100/100]\n","2021-12-21 01:33:16.715074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","INFO:tensorflow:Inference Time : 2.49725s\n","I1221 01:33:16.742501 139879459252096 evaluation.py:273] Inference Time : 2.49725s\n","INFO:tensorflow:Finished evaluation at 2021-12-21-01:33:16\n","I1221 01:33:16.742736 139879459252096 evaluation.py:276] Finished evaluation at 2021-12-21-01:33:16\n","INFO:tensorflow:Saving dict for global step 3910: accuracy = 0.511875, accuracy_top_5 = 0.9140625, global_step = 3910, loss = 1.4425942\n","I1221 01:33:16.742925 139879459252096 estimator.py:2053] Saving dict for global step 3910: accuracy = 0.511875, accuracy_top_5 = 0.9140625, global_step = 3910, loss = 1.4425942\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3910: /root/models/cnn_medium_2A1W/model.ckpt-3910\n","I1221 01:33:17.119622 139879459252096 estimator.py:2113] Saving 'checkpoint_path' summary for global step 3910: /root/models/cnn_medium_2A1W/model.ckpt-3910\n","INFO:tensorflow:Loss for final step: 0.48419467.\n","I1221 01:33:17.266314 139879459252096 estimator.py:375] Loss for final step: 0.48419467.\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from riptide.binary.binary_funcs import *\n","from riptide.binary.binary_layers import Config\n","from riptide.get_models import get_model\n","actQ = DQuantize\n","weightQ = XQuantize\n","config = Config(actQ=actQ, weightQ=weightQ, bits=2.0)\n","with config:\n","  model = get_model('cnn_medium')"],"metadata":{"id":"2HtjumRabEZV","executionInfo":{"status":"ok","timestamp":1640050499788,"user_tz":480,"elapsed":1818,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import tvm\n","from tvm import relay\n","mod, params = relay.frontend.from_keras(\n","  model, \n","  shape={'input_1': [1, 32, 32, 3]}, \n","  layout='NHWC')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"id":"ii1GJ43QoJex","executionInfo":{"status":"error","timestamp":1640050530347,"user_tz":480,"elapsed":544,"user":{"displayName":"bill zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12377542675288155610"}},"outputId":"f57929d7-0e4f-40bc-9727-551e0d35e306"},"execution_count":11,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-0644c4894de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m mod, params = relay.frontend.from_keras(\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'relay' from 'tvm' (unknown location)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":[""],"metadata":{"id":"W_0M_hTVoRQd"},"execution_count":null,"outputs":[]}]}